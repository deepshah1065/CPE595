{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c320ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "\n",
    "seasons = [\"2023-24\", \"2024-25\"]\n",
    "dfs = []\n",
    "\n",
    "for season in seasons:\n",
    "    gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "        season_nullable=season,\n",
    "        season_type_nullable=\"Regular Season\"\n",
    "    )\n",
    "    df = gamefinder.get_data_frames()[0]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "league_games = pd.concat(dfs, ignore_index = True)\n",
    "\n",
    "#No Duplicates\n",
    "league_games = league_games.drop_duplicates(subset=[\"GAME_ID\"])\n",
    "DroppedNAN = league_games.dropna(subset=['PTS', 'AST', 'REB', 'TOV', 'PLUS_MINUS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'WL'])\n",
    "\n",
    "\n",
    "DroppedNAN.to_csv(\"NBA_Dataset.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f357767",
   "metadata": {},
   "outputs": [],
   "source": [
    "uiHomeTeam = input(\"Select the 1st NBA team: \")\n",
    "uiAwayTeam = input(\"Select the 2nd NBA team: \")\n",
    "\n",
    "df = pd.read_csv(\"NBA_Dataset.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Convert W/L to 1/0\n",
    "df[\"WL\"] = df[\"WL\"].map({\"W\": 1, \"L\": 0}).astype(int)\n",
    "\n",
    "FEATURES = [\"PTS\",\"REB\",\"AST\",\"TOV\",\"PLUS_MINUS\",\"FG_PCT\",\"FG3_PCT\",\"FT_PCT\"]\n",
    "X = df[FEATURES]\n",
    "y = df[\"WL\"].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Fit MiniBatchKMeans on TRAIN only\n",
    "k = 6\n",
    "mbk = MiniBatchKMeans(n_clusters=k, batch_size=256, random_state=42)\n",
    "mbk.fit(X_train)\n",
    "\n",
    "# Cluster assignments\n",
    "train_clusters = mbk.predict(X_train)\n",
    "test_clusters  = mbk.predict(X_test)\n",
    "\n",
    "train_cluster_win = pd.Series(y_train).groupby(train_clusters).mean()\n",
    "\n",
    "global_win = float(np.mean(y_train))\n",
    "cluster_win_prob = np.array([float(train_cluster_win.get(i, global_win)) for i in range(k)])\n",
    "\n",
    "df[\"Cluster\"] = mbk.predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34994ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team-level feature averages\n",
    "team_averages = df.groupby(\"TEAM_NAME\")[FEATURES].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a627c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_last_n_games(team_name, n=5):\n",
    "    team_games = df[df[\"TEAM_NAME\"] == team_name].tail(n)\n",
    "    return team_games[FEATURES].mean().values\n",
    "\n",
    "def raw_win_probability(stats):\n",
    "    # Convert a stats vector into a win-probability using cluster distances.\n",
    "    scaled = scaler.transform([stats])\n",
    "    distances = mbk.transform(scaled)[0]          # shape: (k,)\n",
    "    weights = softmax(-distances)                # closer clusters get higher weight\n",
    "    return float(weights @ cluster_win_prob)      # weighted avg of per-cluster win rates\n",
    "\n",
    "def normalize_probs(pA, pB):\n",
    "    total = pA + pB\n",
    "    return pA / total, pB / total\n",
    "\n",
    "def predict_future_game(teamA_name, teamB_name, n=5):\n",
    "    teamA_stats = get_last_n_games(teamA_name, n)\n",
    "    teamB_stats = get_last_n_games(teamB_name, n)\n",
    "\n",
    "    rawA = raw_win_probability(teamA_stats)\n",
    "    rawB = raw_win_probability(teamB_stats)\n",
    "\n",
    "    probA, probB = normalize_probs(rawA, rawB)\n",
    "    winner = teamA_name if probA > probB else teamB_name\n",
    "\n",
    "    print(\"ðŸ€ Future Game Prediction\")\n",
    "    print(\"Predicted Winner:\", winner)\n",
    "    print(f\"{teamA_name} Win Probability: {probA:.2%}\")\n",
    "    print(f\"{teamB_name} Win Probability: {probB:.2%}\")\n",
    "\n",
    "    return winner, probA, probB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da434c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy (full data): 77.51%\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def kmeans_win_proba(Xs_scaled):\n",
    "    distances = mbk.transform(Xs_scaled)                 # (n, k)\n",
    "    weights = softmax(-distances, axis=1)               # row-wise\n",
    "    return (weights @ cluster_win_prob).astype(float)   # (n,)\n",
    "\n",
    "# Add per-game predicted probability/label for the full dataset\n",
    "p_all = kmeans_win_proba(X_scaled)\n",
    "df[\"Predicted_Prob\"] = p_all\n",
    "df[\"Predicted_WL\"] = (p_all >= 0.5).astype(int)\n",
    "\n",
    "accuracy = (df[\"Predicted_WL\"] == df[\"WL\"]).mean()\n",
    "print(f\"Model Accuracy (full data): {accuracy:.2%}\")\n",
    "\n",
    "# Holdout outputs for evaluation in the next cell\n",
    "p_test = kmeans_win_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KMEANS-PROB TEST\n",
      "  logloss : 0.5119480515438987\n",
      "  brier   : 0.16508333798372476\n",
      "  auc     : 0.8949344270428499\n",
      "  acc     : 0.8048780487804879\n",
      "ðŸ€ Future Game Prediction\n",
      "Predicted Winner: New York Knicks\n",
      "New York Knicks Win Probability: 63.63%\n",
      "San Antonio Spurs Win Probability: 36.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\denni\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('New York Knicks', 0.6362923793383006, 0.36370762066169937)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, brier_score_loss\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def eval_prob_model(name, y_true, p):\n",
    "    \"\"\"Evaluation for a model that outputs win probabilities (supervised metrics).\"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    p = np.asarray(p).astype(float)\n",
    "\n",
    "    pred = (p >= 0.5).astype(int)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"  logloss :\", log_loss(y_true, p))\n",
    "    print(\"  brier   :\", brier_score_loss(y_true, p))\n",
    "\n",
    "    # ROC AUC needs both classes present\n",
    "    if len(np.unique(y_true)) > 1:\n",
    "        print(\"  auc     :\", roc_auc_score(y_true, p))\n",
    "    else:\n",
    "        print(\"  auc     : N/A (single class in y_true)\")\n",
    "\n",
    "    print(\"  acc     :\", accuracy_score(y_true, pred))\n",
    "\n",
    "# ---- Evaluations ----\n",
    "test_clusters = mbk.predict(X_test)\n",
    "\n",
    "eval_prob_model(\"KMEANS-PROB TEST\", y_test, p_test)\n",
    "\n",
    "# ---- Predict the user-selected matchup ----\n",
    "predict_future_game(uiHomeTeam, uiAwayTeam)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
